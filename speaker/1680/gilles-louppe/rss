<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>pyvideo.org: Videos of Gilles Louppe</title><link>http://www.pyvideo.org/speaker/1680/gilles-louppe/rss</link><description></description><atom:link href="http://www.pyvideo.org/speaker/1680/gilles-louppe/rss" rel="self"></atom:link><language>en-us</language><lastBuildDate>Mon, 13 Apr 2015 00:00:00 -0500</lastBuildDate><ttl>500</ttl><item><title>Tree models with scikit-learn</title><link>http://www.pyvideo.org/video/3521/tree-models-with-scikit-learn</link><description>&lt;p&gt;Description&lt;/p&gt;
This talk gives an introduction to tree-based methods, both from a theoretical and practical point of view. It covers decision trees, random forests and boosting estimators, along with concrete examples based on Scikit-Learn about how they work, when they work and why they work.</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Gilles Louppe</dc:creator><pubDate>Mon, 13 Apr 2015 00:00:00 -0500</pubDate><guid>http://www.pyvideo.org/video/3521/tree-models-with-scikit-learn</guid><enclosure url="https://www.youtube.com/watch?v=GuRfLbAU9Ho" length="None" type="video/flv"></enclosure><media:thumbnail url="https://i.ytimg.com/vi/GuRfLbAU9Ho/hqdefault.jpg"></media:thumbnail></item><item><title>Accelerating Random Forests in Scikit Learn</title><link>http://www.pyvideo.org/video/3334/accelerating-random-forests-in-scikit-learn</link><description>&lt;p&gt;Description&lt;/p&gt;
Random Forests are without contest one of the most robust, accurate and versatile tools for solving machine learning tasks. Implementing this algorithm properly and efficiently remains however a challenging task involving issues that are easily overlooked if not considered with care. In this talk, we present the Random Forests implementation developed within the Scikit-Learn machine learning library. In particular, we describe the iterative team efforts that led us to gradually improve our codebase and eventually make Scikit-Learn's Random Forests one of the most efficient implementations in the scientific ecosystem, across all libraries and programming languages. Algorithmic and technical optimizations that have made this possible include:

* An efficient formulation of the decision tree algorithm, tailored for Random Forests;
* Cythonization of the tree induction algorithm;
* CPU cache optimizations, through low-level organization of data into contiguous memory blocks;
* Efficient multi-threading through GIL-free routines;
* A dedicated sorting procedure, taking into account the properties of data;
* Shared pre-computations whenever critical.

Overall, we believe that lessons learned from this case study extend to a broad range of scientific applications and may be of interest to anybody doing data analysis in Python.</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Gilles Louppe</dc:creator><pubDate>Wed, 22 Oct 2014 00:00:00 -0500</pubDate><guid>http://www.pyvideo.org/video/3334/accelerating-random-forests-in-scikit-learn</guid><enclosure url="https://www.youtube.com/watch?v=TqF0rKzvjm4" length="None" type="video/flv"></enclosure><media:thumbnail url="https://i.ytimg.com/vi/TqF0rKzvjm4/hqdefault.jpg"></media:thumbnail></item></channel></rss>