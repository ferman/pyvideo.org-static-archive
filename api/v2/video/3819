{"category": "PyGotham 2015", "language": "English", "slug": "going-parallel-and-out-of-core-with-task-scheduli", "speakers": ["Blake Griffith"], "tags": [], "related_urls": [], "id": 3819, "state": 1, "title": "Going parallel and larger-than-memory with graphs", "summary": "", "description": "Dask is an open source, pure python library that enables parallel larger-than-memory computation in a novel way. We represent programs as Directed Acyclic Graphs (DAG) of function calls. These graphs are executed by dask's schedulers with different optimizations (synchronous, threaded, parallel, distributed-memory). Dask has modules geared towards data analysis, which provide a friendly interface to building graps. One module, dask.array, mimics a subset of NumPy operations. With dask.array we can work with NumPy like arrays that are larger than RAM and parallelization comes for free by leveraging the underlying DAG.", "quality_notes": "", "copyright_text": "CC BY-SA", "embed": "", "thumbnail_url": "https://i.ytimg.com/vi/yDlCNjtZvLw/hqdefault.jpg", "duration": 2553, "video_ogv_length": null, "video_ogv_url": null, "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "http://64966d3674e0a64d8f4a-47c94b14ef8e1f83d5390cdb0629c6ed.r53.cf2.rackcdn.com/pygotham-2015/3819_Going_parallel_and_outofcore_with_task_scheduling.mp4", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "http://youtu.be/yDlCNjtZvLw", "whiteboard": "", "recorded": "2015-08-16", "added": "2015-08-10T15:48:57.562", "updated": "2015-08-28T14:18:24.893"}